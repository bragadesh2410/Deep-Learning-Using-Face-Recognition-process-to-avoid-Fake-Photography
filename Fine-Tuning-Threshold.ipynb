{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: deepfaceNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Version: 0.0.75\n",
      "Summary: A Lightweight Face Recognition and Facial Attribute Analysis Framework (Age, Gender, Emotion, Race) for Python\n",
      "Home-page: https://github.com/serengil/deepface\n",
      "Author: Sefik Ilkin Serengil\n",
      "Author-email: serengil@gmail.com\n",
      "License: UNKNOWN\n",
      "Location: c:\\users\\admin\\anaconda3\\lib\\site-packages\n",
      "Requires: fire, Flask, gdown, keras, mtcnn, numpy, opencv-python, pandas, Pillow, retina-face, tensorflow, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "pip show --version deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Face recognition models are regular convolutional neural networks models. They represent face photos as vectors. We find the distance between these two vectors to compare two faces. Finally, we classify two faces as same person whose distance is less than a threshold value.\n",
    "\n",
    "The question is that how to determine the threshold. In this notebook, we will find the best split point for a threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://github.com/serengil/deepface/tree/master/tests/dataset\n",
    "idendities = {\n",
    "    \"Angelina\": [\"img1.jpg\", \"img2.jpg\", \"img4.jpg\", \"img5.jpg\", \"img6.jpg\", \"img7.jpg\", \"img10.jpg\", \"img11.jpg\"],\n",
    "    \"Scarlett\": [\"img8.jpg\", \"img9.jpg\"],\n",
    "    \"Jennifer\": [\"img3.jpg\", \"img12.jpg\"],\n",
    "    \"Mark\": [\"img13.jpg\", \"img14.jpg\", \"img15.jpg\"],\n",
    "    \"Jack\": [\"img16.jpg\", \"img17.jpg\"],\n",
    "    \"Elon\": [\"img18.jpg\", \"img19.jpg\"],\n",
    "    \"Jeff\": [\"img20.jpg\", \"img21.jpg\"],\n",
    "    \"Marissa\": [\"img22.jpg\", \"img23.jpg\"],\n",
    "    \"Sundar\": [\"img24.jpg\", \"img25.jpg\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive samples\n",
    "Find different photos of same people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = []\n",
    "\n",
    "for key, values in idendities.items():\n",
    "    \n",
    "    #print(key)\n",
    "    for i in range(0, len(values)-1):\n",
    "        for j in range(i+1, len(values)):\n",
    "            #print(values[i], \" and \", values[j])\n",
    "            positive = []\n",
    "            positive.append(values[i])\n",
    "            positive.append(values[j])\n",
    "            positives.append(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = pd.DataFrame(positives, columns = [\"file_x\", \"file_y\"])\n",
    "positives[\"decision\"] = \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative samples\n",
    "Compare photos of different people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Angelina': ['img1.jpg', 'img2.jpg', 'img4.jpg', 'img5.jpg', 'img6.jpg', 'img7.jpg', 'img10.jpg', 'img11.jpg'], 'Scarlett': ['img8.jpg', 'img9.jpg'], 'Jennifer': ['img3.jpg', 'img12.jpg'], 'Mark': ['img13.jpg', 'img14.jpg', 'img15.jpg'], 'Jack': ['img16.jpg', 'img17.jpg'], 'Elon': ['img18.jpg', 'img19.jpg'], 'Jeff': ['img20.jpg', 'img21.jpg'], 'Marissa': ['img22.jpg', 'img23.jpg'], 'Sundar': ['img24.jpg', 'img25.jpg']}\n"
     ]
    }
   ],
   "source": [
    "samples_list = list(idendities.values())\n",
    "print(idendities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = []\n",
    "\n",
    "for i in range(0, len(idendities) - 1):\n",
    "    for j in range(i+1, len(idendities)):\n",
    "        #print(samples_list[i], \" vs \",samples_list[j]) \n",
    "        cross_product = itertools.product(samples_list[i], samples_list[j])\n",
    "        cross_product = list(cross_product)\n",
    "        #print(cross_product)\n",
    "        \n",
    "        for cross_sample in cross_product:\n",
    "            #print(cross_sample[0], \" vs \", cross_sample[1])\n",
    "            negative = []\n",
    "            negative.append(cross_sample[0])\n",
    "            negative.append(cross_sample[1])\n",
    "            negatives.append(negative)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = pd.DataFrame(negatives, columns = [\"file_x\", \"file_y\"])\n",
    "negatives[\"decision\"] = \"No\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Positives and Negative Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([positives, negatives]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     262\n",
       "Yes     38\n",
       "Name: decision, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.decision.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.file_x = \"deepface/tests/dataset/\"+df.file_x\n",
    "df.file_y = \"deepface/tests/dataset/\"+df.file_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img2.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img4.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img5.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img6.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img7.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img10.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img11.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img4.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img5.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img6.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img7.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img10.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img11.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img5.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img6.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img7.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img10.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img11.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img6.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img7.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img10.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img11.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img7.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img10.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img11.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img10.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img11.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img11.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img9.jpg'], ['deepface/tests/dataset/img3.jpg', 'deepface/tests/dataset/img12.jpg'], ['deepface/tests/dataset/img13.jpg', 'deepface/tests/dataset/img14.jpg'], ['deepface/tests/dataset/img13.jpg', 'deepface/tests/dataset/img15.jpg'], ['deepface/tests/dataset/img14.jpg', 'deepface/tests/dataset/img15.jpg'], ['deepface/tests/dataset/img16.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img18.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img20.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img22.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img24.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img8.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img9.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img8.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img9.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img8.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img9.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img8.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img9.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img8.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img9.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img8.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img9.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img8.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img9.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img8.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img9.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img3.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img12.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img3.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img12.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img3.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img12.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img3.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img12.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img3.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img12.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img3.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img12.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img3.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img12.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img3.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img12.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img13.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img14.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img15.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img13.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img14.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img15.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img13.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img14.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img15.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img13.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img14.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img15.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img13.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img14.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img15.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img13.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img14.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img15.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img13.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img14.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img15.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img13.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img14.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img15.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img16.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img16.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img16.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img16.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img16.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img16.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img16.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img16.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img1.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img2.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img4.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img5.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img6.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img7.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img10.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img11.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img3.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img12.jpg'], ['deepface/tests/dataset/img9.jpg', 'deepface/tests/dataset/img3.jpg'], ['deepface/tests/dataset/img9.jpg', 'deepface/tests/dataset/img12.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img13.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img14.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img15.jpg'], ['deepface/tests/dataset/img9.jpg', 'deepface/tests/dataset/img13.jpg'], ['deepface/tests/dataset/img9.jpg', 'deepface/tests/dataset/img14.jpg'], ['deepface/tests/dataset/img9.jpg', 'deepface/tests/dataset/img15.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img16.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img9.jpg', 'deepface/tests/dataset/img16.jpg'], ['deepface/tests/dataset/img9.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img9.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img9.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img9.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img9.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img9.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img9.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img8.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img9.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img9.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img3.jpg', 'deepface/tests/dataset/img13.jpg'], ['deepface/tests/dataset/img3.jpg', 'deepface/tests/dataset/img14.jpg'], ['deepface/tests/dataset/img3.jpg', 'deepface/tests/dataset/img15.jpg'], ['deepface/tests/dataset/img12.jpg', 'deepface/tests/dataset/img13.jpg'], ['deepface/tests/dataset/img12.jpg', 'deepface/tests/dataset/img14.jpg'], ['deepface/tests/dataset/img12.jpg', 'deepface/tests/dataset/img15.jpg'], ['deepface/tests/dataset/img3.jpg', 'deepface/tests/dataset/img16.jpg'], ['deepface/tests/dataset/img3.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img12.jpg', 'deepface/tests/dataset/img16.jpg'], ['deepface/tests/dataset/img12.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img3.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img3.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img12.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img12.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img3.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img3.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img12.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img12.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img3.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img3.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img12.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img12.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img3.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img3.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img12.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img12.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img13.jpg', 'deepface/tests/dataset/img16.jpg'], ['deepface/tests/dataset/img13.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img14.jpg', 'deepface/tests/dataset/img16.jpg'], ['deepface/tests/dataset/img14.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img15.jpg', 'deepface/tests/dataset/img16.jpg'], ['deepface/tests/dataset/img15.jpg', 'deepface/tests/dataset/img17.jpg'], ['deepface/tests/dataset/img13.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img13.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img14.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img14.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img15.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img15.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img13.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img13.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img14.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img14.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img15.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img15.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img13.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img13.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img14.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img14.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img15.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img15.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img13.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img13.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img14.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img14.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img15.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img15.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img16.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img16.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img17.jpg', 'deepface/tests/dataset/img18.jpg'], ['deepface/tests/dataset/img17.jpg', 'deepface/tests/dataset/img19.jpg'], ['deepface/tests/dataset/img16.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img16.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img17.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img17.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img16.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img16.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img17.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img17.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img16.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img16.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img17.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img17.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img18.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img18.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img19.jpg', 'deepface/tests/dataset/img20.jpg'], ['deepface/tests/dataset/img19.jpg', 'deepface/tests/dataset/img21.jpg'], ['deepface/tests/dataset/img18.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img18.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img19.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img19.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img18.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img18.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img19.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img19.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img20.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img20.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img21.jpg', 'deepface/tests/dataset/img22.jpg'], ['deepface/tests/dataset/img21.jpg', 'deepface/tests/dataset/img23.jpg'], ['deepface/tests/dataset/img20.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img20.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img21.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img21.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img22.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img22.jpg', 'deepface/tests/dataset/img25.jpg'], ['deepface/tests/dataset/img23.jpg', 'deepface/tests/dataset/img24.jpg'], ['deepface/tests/dataset/img23.jpg', 'deepface/tests/dataset/img25.jpg']]\n"
     ]
    }
   ],
   "source": [
    "instances = df[[\"file_x\", \"file_y\"]].values.tolist()\n",
    "print(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"VGG-Face\"\n",
    "distance_metric = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 0EAE-C834\n",
      "\n",
      " Directory of C:\\Users\\admin\\projects\\dp-new\\dp-new\n",
      "\n",
      "17-02-2024  22:30    <DIR>          .\n",
      "17-02-2024  22:30    <DIR>          ..\n",
      "14-03-2023  14:50    <DIR>          .github\n",
      "21-11-2022  10:28               424 .gitignore\n",
      "15-03-2023  07:18    <DIR>          .ipynb_checkpoints\n",
      "14-03-2023  14:50    <DIR>          api\n",
      "15-03-2023  07:18    <DIR>          deepface\n",
      "21-11-2022  10:28               215 Dockerfile\n",
      "17-02-2024  22:30            52,805 Fine-Tuning-Threshold.ipynb\n",
      "14-03-2023  14:50    <DIR>          icon\n",
      "21-11-2022  10:28             1,076 LICENSE\n",
      "21-11-2022  10:28            21,277 README.md\n",
      "21-11-2022  11:39               365 requirements.txt\n",
      "14-03-2023  14:50    <DIR>          scripts\n",
      "21-11-2022  10:28             1,089 setup.py\n",
      "15-03-2023  07:59    <DIR>          tests\n",
      "               7 File(s)         77,251 bytes\n",
      "               9 Dir(s)  158,392,287,232 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Confirm that ', 'dp-new/tests/dataset/img1.jpg', ' exists')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7424\\3635053990.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresp_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeepFace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"dp-new/tests/dataset/img1.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg2_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"dp-new/tests/dataset/img2.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistance_metric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\projects\\dp-new\\dp-new\\deepface\\DeepFace.py\u001b[0m in \u001b[0;36mverify\u001b[1;34m(img1_path, img2_path, model_name, distance_metric, model, enforce_detection, detector_backend, align, prog_bar, normalization)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                                 \u001b[1;31m#img_path, model_name = 'VGG-Face', model = None, enforce_detection = True, detector_backend = 'mtcnn'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m \t\t\t\timg1_representation = represent(img_path = img1_path\n\u001b[0m\u001b[0;32m    163\u001b[0m                                                 \u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustom_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                                                 \u001b[1;33m,\u001b[0m \u001b[0menforce_detection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menforce_detection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetector_backend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\projects\\dp-new\\dp-new\\deepface\\DeepFace.py\u001b[0m in \u001b[0;36mrepresent\u001b[1;34m(img_path, model_name, model, enforce_detection, detector_backend, align, normalization)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;31m#detect and align\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m \timg = functions.preprocess_face(img = img_path\n\u001b[0m\u001b[0;32m    755\u001b[0m                 \u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                 \u001b[1;33m,\u001b[0m \u001b[0menforce_detection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menforce_detection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\projects\\dp-new\\dp-new\\deepface\\commons\\functions.py\u001b[0m in \u001b[0;36mpreprocess_face\u001b[1;34m(img, target_size, grayscale, enforce_detection, detector_backend, return_region, align)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;31m#img might be path, base64 or numpy array. Convert it to numpy whatever it is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[0mbase_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\projects\\dp-new\\dp-new\\deepface\\commons\\functions.py\u001b[0m in \u001b[0;36mload_image\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mexact_image\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#image path passed as input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Confirm that \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ('Confirm that ', 'dp-new/tests/dataset/img1.jpg', ' exists')"
     ]
    }
   ],
   "source": [
    "resp_obj = DeepFace.verify(img1_path = \"deepface/tests/dataset/img1.jpg\", img2_path = \"deepface/tests/dataset/img2.jpg\", model_name = model_name, distance_metric = distance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_obj = DeepFace.verify(instances, model_name = model_name, distance_metric = distance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "for i in range(0, len(instances)):\n",
    "    distance = round(resp_obj[\"pair_%s\" % (i+1)][\"distance\"], 4)\n",
    "    distances.append(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"distance\"] = distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_mean = round(df[df.decision == \"Yes\"].mean().values[0], 4)\n",
    "tp_std = round(df[df.decision == \"Yes\"].std().values[0], 4)\n",
    "fp_mean = round(df[df.decision == \"No\"].mean().values[0], 4)\n",
    "fp_std = round(df[df.decision == \"No\"].std().values[0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean of true positives: \", tp_mean)\n",
    "print(\"Std of true positives: \", tp_std)\n",
    "print(\"Mean of false positives: \", fp_mean)\n",
    "print(\"Std of false positives: \", fp_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.decision == \"Yes\"].distance.plot.kde()\n",
    "df[df.decision == \"No\"].distance.plot.kde()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Split Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chefboost import Chefboost as chef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'algorithm': 'C4.5'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df[['distance', 'decision']].rename(columns = {\"decision\": \"Decision\"}).copy()\n",
    "model = chef.fit(tmp_df, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 2\n",
    "#2 sigma corresponds 95.45% confidence, and 3 sigma corresponds 99.73% confidence\n",
    "\n",
    "#threshold = round(tp_mean + sigma * tp_std, 4)\n",
    "threshold = 0.3147 #comes from c4.5 algorithm\n",
    "print(\"threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.decision == 'Yes'].distance.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.decision == 'No'].distance.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prediction\"] = \"No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df[df.distance <= threshold].index\n",
    "df.loc[idx, 'prediction'] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(df.decision.values, df.prediction.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = cm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "accuracy = (tp + tn)/(tn + fp +  fn + tp)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision: \", 100*precision,\"%\")\n",
    "print(\"Recall: \", 100*recall,\"%\")\n",
    "print(\"F1 score \",100*f1, \"%\")\n",
    "print(\"Accuracy: \", 100*accuracy,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"threshold_pivot.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results\n",
    "\n",
    "### Threshold = 0.3147 (C4.5 best split point)\n",
    "\n",
    "Precision:  100.0 %\n",
    "\n",
    "Recall:  89.47368421052632 %\n",
    "\n",
    "F1 score  94.44444444444444%\n",
    "\n",
    "Accuracy:  98.66666666666667 %\n",
    "\n",
    "### Threshold = 0.3751 (2 sigma)\n",
    "\n",
    "Precision:  90.47619047619048 %\n",
    "\n",
    "Recall:  100.0 %\n",
    "\n",
    "F1 score  95.0 %\n",
    "\n",
    "Accuracy:  98.66666666666667 %"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
